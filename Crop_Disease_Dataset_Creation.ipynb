{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ItcBGcniu_W8"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('YOUR_API_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('YOUR_USERNAME')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "!kaggle datasets download -d badhon7432/paddyleafdiseaseuci"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVqU57ty_VxN",
        "outputId": "e6f14260-6cb3-4930-8601-223384337fc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading paddyleafdiseaseuci.zip to /content\n",
            " 97% 157M/161M [00:03<00:00, 36.2MB/s]\n",
            "100% 161M/161M [00:03<00:00, 43.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plant_Leaf_disease"
      ],
      "metadata": {
        "id": "qJIvjX58Ein3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "downloaded_dataset_path = \"paddyleafdiseaseuci.zip\"\n",
        "extracted_dataset_path = \"paddyleafdiseaseuci\"\n",
        "train_folder_path = os.path.join(extracted_dataset_path, \"train\")\n",
        "desired_folders = [\"Bacterial leaf blight\", \"Brown spot\", \"Leaf smut\"]\n",
        "\n",
        "with zipfile.ZipFile(downloaded_dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dataset_path)\n",
        "\n",
        "# Create new dataset directory\n",
        "os.makedirs(\"crop_diseases\", exist_ok=True)\n",
        "\n",
        "# Traverse train folder and copy desired folders to new dataset directory\n",
        "for root, dirs, files in os.walk(train_folder_path):\n",
        "    for folder in dirs:\n",
        "        if folder in desired_folders:\n",
        "            shutil.copytree(os.path.join(root, folder), os.path.join(\"crop_diseases\", folder))\n",
        "\n",
        "print(\"New dataset created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65C2ig5q7E9V",
        "outputId": "2545cee5-a4df-4c11-e60c-d92894d01af9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abdallahalidev/plantvillage-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fmwhD3dAWel",
        "outputId": "ac8ac810-d648-4ed0-d6c8-adfe712a8d24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading plantvillage-dataset.zip to /content\n",
            "100% 2.03G/2.04G [00:27<00:00, 81.1MB/s]\n",
            "100% 2.04G/2.04G [00:27<00:00, 79.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plant_village_dataset"
      ],
      "metadata": {
        "id": "RQadW2B0Em3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Function to copy folders from one directory to another\n",
        "def copy_folders(source_dir, destination_dir, folders):\n",
        "    for folder in folders:\n",
        "        shutil.copytree(os.path.join(source_dir, folder), os.path.join(destination_dir, folder))\n",
        "\n",
        "# Path for the downloaded plantvillage-dataset ZIP file\n",
        "new_downloaded_dataset_path = \"/content/plantvillage-dataset.zip\"\n",
        "\n",
        "# Extracted dataset directory for the new dataset\n",
        "new_extracted_dataset_path = \"/content/plantvillage-dataset/plantvillage dataset/color\"\n",
        "\n",
        "# Desired folders to be copied from the new dataset\n",
        "new_desired_folders = [\n",
        "    \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\n",
        "    \"Corn_(maize)___Common_rust_\",\n",
        "    \"Corn_(maize)___Northern_Leaf_Blight\",\n",
        "    \"Corn_(maize)___healthy\",\n",
        "    \"Grape___Black_rot\",\n",
        "    \"Grape___Esca_(Black_Measles)\",\n",
        "    \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
        "    \"Grape___healthy\",\n",
        "    \"Potato___Early_blight\",\n",
        "    \"Potato___Late_blight\",\n",
        "    \"Potato___healthy\",\n",
        "    \"Tomato___Bacterial_spot\",\n",
        "    \"Tomato___Early_blight\",\n",
        "    \"Tomato___Late_blight\",\n",
        "    \"Tomato___Leaf_Mold\",\n",
        "    \"Tomato___Septoria_leaf_spot\",\n",
        "    \"Tomato___Target_Spot\",\n",
        "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
        "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
        "    \"Tomato___Tomato_mosaic_virus\",\n",
        "    \"Tomato___healthy\"\n",
        "]\n",
        "\n",
        "# Append desired folders from the new dataset to crop_diseases directory\n",
        "copy_folders(new_extracted_dataset_path, \"crop_diseases\", new_desired_folders)\n",
        "\n",
        "print(\"Selected folders from the new dataset have been appended to crop_diseases directory successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryBQTRcyDkTa",
        "outputId": "05561ef4-df8b-4b62-c57d-7e3eea187f86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected folders from the new dataset have been appended to crop_diseases directory successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bangladesh_crop disease"
      ],
      "metadata": {
        "id": "0-F_aRtCEpnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nafishamoin/new-bangladeshi-crop-disease"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEtbTf7OEzYQ",
        "outputId": "f5bc588e-70b3-4787-9637-49ea870c8181"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading new-bangladeshi-crop-disease.zip to /content\n",
            "100% 2.35G/2.35G [01:16<00:00, 30.5MB/s]\n",
            "100% 2.35G/2.35G [01:16<00:00, 32.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path for the downloaded new-bangladeshi-crop-disease ZIP file\n",
        "new_downloaded_dataset_path = \"/content/new-bangladeshi-crop-disease.zip\""
      ],
      "metadata": {
        "id": "u_DvRpeZFL9C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_extracted_dataset_path = \"/content/new-bangladeshi-crop-disease/BangladeshiCrops/BangladeshiCrops/Crop___Disease/Wheat\""
      ],
      "metadata": {
        "id": "dyaYOdW8FQoP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to copy folders from one directory to another\n",
        "def copy_folders(source_dir, destination_dir, folders):\n",
        "    for folder in folders:\n",
        "        shutil.copytree(os.path.join(source_dir, folder), os.path.join(destination_dir, folder))\n",
        "\n",
        "# Desired folders to be copied from the new dataset\n",
        "new_desired_folders = [\n",
        "    \"Wheat___Brown_Rust\",\n",
        "    \"Wheat___Healthy\",\n",
        "    \"Wheat___Yellow_Rust\",\n",
        "]\n",
        "\n",
        "# Extract the new dataset\n",
        "with zipfile.ZipFile(new_downloaded_dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(new_extracted_dataset_path)\n",
        "\n",
        "# Append desired folders from the new dataset to crop_diseases directory\n",
        "copy_folders(new_extracted_dataset_path, \"crop_diseases\", new_desired_folders)\n",
        "\n",
        "print(\"Selected folders from the new dataset have been appended to crop_diseases directory successfully!\")\n"
      ],
      "metadata": {
        "id": "PbSO6EdUB-Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20K multi class crop dataset"
      ],
      "metadata": {
        "id": "ntEnpO4s2PR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jawadali1045/20k-multi-class-crop-disease-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X75ZhU55HKno",
        "outputId": "e19c9d71-c6eb-4c7b-e089-51e1b563589e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 20k-multi-class-crop-disease-images.zip to /content\n",
            "100% 2.34G/2.34G [00:46<00:00, 76.4MB/s]\n",
            "100% 2.34G/2.34G [00:46<00:00, 53.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_downloaded_dataset_path = \"/content/20k-multi-class-crop-disease-images.zip\""
      ],
      "metadata": {
        "id": "P52fh8JiIlH3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_extracted_dataset_path = \"/content/20k-multi-class-crop-disease-images/Train/Train\""
      ],
      "metadata": {
        "id": "8kOg07VpIdbG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_folders(source_dir, destination_dir, folders):\n",
        "    for folder in folders:\n",
        "        # Check if the folder already exists in the destination directory\n",
        "        if not os.path.exists(os.path.join(destination_dir, folder)):\n",
        "            shutil.copytree(os.path.join(source_dir, folder), os.path.join(destination_dir, folder))\n",
        "        else:\n",
        "            print(f\"Folder '{folder}' already exists in the destination directory. Skipping...\")\n",
        "\n",
        "# Desired folders to be copied from the new dataset\n",
        "new_desired_folders = [\n",
        "    \"Anthracnose on Cotton\",\n",
        "    \"Becterial Blight in Rice\",\n",
        "    \"Brownspot\",\n",
        "    \"Common_Rust\",\n",
        "    \"Flag Smut\",\n",
        "    \"Gray_Leaf_Spot\",\n",
        "    \"Healthy Maize\",\n",
        "    \"Healthy Wheat\",\n",
        "    \"Healthy cotton\",\n",
        "    \"Leaf Curl\",\n",
        "    \"Leaf smut\",\n",
        "    \"Mosaic sugarcane\",\n",
        "    \"RedRot sugarcane\",\n",
        "    \"RedRust sugarcane\",\n",
        "    \"Rice Blast\",\n",
        "    \"Sugarcane Healthy\",\n",
        "    \"Tungro\",\n",
        "    \"Wheat Brown leaf Rust\",\n",
        "    \"Wheat Stem fly\",\n",
        "    \"Wheat aphid\",\n",
        "    \"Wheat black rust\",\n",
        "    \"Wheat leaf blight\",\n",
        "    \"Wheat powdery mildew\",\n",
        "    \"Wheat scab\",\n",
        "    \"Wheat___Yellow_Rust\",\n",
        "    \"Wilt\"\n",
        "]\n",
        "\n",
        "copy_folders(new_extracted_dataset_path, \"crop_diseases\", new_desired_folders)\n",
        "\n",
        "print(\"Selected folders from the new dataset have been appended to crop_diseases directory successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl8MUPsqH_3D",
        "outputId": "b60cb079-5e1d-4073-d18d-a4dc2a6689f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'Anthracnose on Cotton' already exists in the destination directory. Skipping...\n",
            "Folder 'Leaf smut' already exists in the destination directory. Skipping...\n",
            "Folder 'Wheat___Yellow_Rust' already exists in the destination directory. Skipping...\n",
            "Selected folders from the new dataset have been appended to crop_diseases directory successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "banana disease"
      ],
      "metadata": {
        "id": "sX0eeDJ12XK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sujaykapadnis/banana-disease-recognition-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0NMsB8JVPo",
        "outputId": "00b08d1b-45d7-4957-bb96-5a1d0a8b03f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading banana-disease-recognition-dataset.zip to /content\n",
            " 99% 120M/122M [00:03<00:00, 36.1MB/s]\n",
            "100% 122M/122M [00:03<00:00, 40.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_downloaded_dataset_path = \"/content/banana-disease-recognition-dataset.zip\""
      ],
      "metadata": {
        "id": "57Ugj4fpL3AU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_extracted_dataset_path = \"/content/banana-disease-recognition-dataset/Banana Disease Recognition Dataset/Original Images/Original Images\""
      ],
      "metadata": {
        "id": "T4g9DeNGLyW3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "\n",
        "# # Path to the downloaded zip file\n",
        "# zip_file_path = \"/content/banana-disease-recognition-dataset.zip\"\n",
        "\n",
        "# # Destination directory for extraction\n",
        "# destination_dir = \"/content/banana-disease-recognition-dataset\"\n",
        "\n",
        "# # Extract the zip file\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(destination_dir)\n"
      ],
      "metadata": {
        "id": "zGU6MNRDOcy9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_folders(source_dir, destination_dir, folders):\n",
        "    for folder in folders:\n",
        "        # Check if the folder already exists in the destination directory\n",
        "        if not os.path.exists(os.path.join(destination_dir, folder)):\n",
        "            shutil.copytree(os.path.join(source_dir, folder), os.path.join(destination_dir, folder))\n",
        "        else:\n",
        "            print(f\"Folder '{folder}' already exists in the destination directory. Skipping...\")\n",
        "\n",
        "# Desired folders to be copied from the new dataset\n",
        "new_desired_folders = [\n",
        "    \"Banana Black Sigatoka Disease\",\n",
        "    \"Banana Bract Mosaic Virus Disease\",\n",
        "    \"Banana Healthy Leaf\",\n",
        "    \"Banana Insect Pest Disease\",\n",
        "    \"Banana Moko Disease\",\n",
        "    \"Banana Panama Disease\",\n",
        "    \"Banana Yellow Sigatoka Disease\",\n",
        "]\n",
        "\n",
        "# Append desired folders from the new dataset to crop_diseases directory\n",
        "copy_folders(new_extracted_dataset_path, \"crop_diseases\", new_desired_folders)\n",
        "\n",
        "print(\"Selected folders from the new dataset have been appended to crop_diseases directory successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PNu6Mq7MDy6",
        "outputId": "a399f81d-9c12-4bcf-90c4-c3794affaf6e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'Banana Black Sigatoka Disease' already exists in the destination directory. Skipping...\n",
            "Folder 'Banana Bract Mosaic Virus Disease' already exists in the destination directory. Skipping...\n",
            "Folder 'Banana Healthy Leaf' already exists in the destination directory. Skipping...\n",
            "Folder 'Banana Insect Pest Disease' already exists in the destination directory. Skipping...\n",
            "Folder 'Banana Moko Disease' already exists in the destination directory. Skipping...\n",
            "Folder 'Banana Panama Disease' already exists in the destination directory. Skipping...\n",
            "Selected folders from the new dataset have been appended to crop_diseases directory successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LH0TVBQqMQdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/crop_diseases.zip'\n",
        "\n",
        "zip_file_size = os.path.getsize(zip_file_path)\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "# Display the size of the zip file\n",
        "print(\"Size of the zip file:\", sizeof_fmt(zip_file_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMN0p_LoUHS-",
        "outputId": "82c253b8-7787-4efc-ddcc-6b45297b386a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the zip file: 2.3GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFH79dR3u6xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Create data generator with validation split\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load the dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/crop_diseases',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    '/content/crop_diseases',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Determine the number of classes dynamically\n",
        "NUM_CLASSES = len(train_generator.class_indices)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(valid_generator)\n",
        "print(f'Validation accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vMqraoFxu6uJ",
        "outputId": "cf2ed1bf-000f-40c1-b32f-01ee16fa8990"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 36739 images belonging to 58 classes.\n",
            "Found 9159 images belonging to 58 classes.\n",
            "Epoch 1/10\n",
            "   6/1148 [..............................] - ETA: 1:41:41 - loss: 4.2995 - accuracy: 0.0156"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-3a14eb444e3a>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThGfQFtd0APK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}